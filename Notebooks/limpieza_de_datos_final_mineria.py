# -*- coding: utf-8 -*-
"""Limpieza_de_datos_final_Mineria.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qdGeZcjfvOaZ-2YMkbp4yXy92Im-TjQJ
"""

!pip install ydata-profiling

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats import chi2_contingency
from sklearn.feature_selection import mutual_info_classif
from scipy.stats import f_oneway
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import LabelEncoder
from imblearn.combine import SMOTETomek
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from ydata_profiling import ProfileReport
from imblearn.combine import SMOTETomek
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

"""## Carga de datos"""

#cargamos los datos
df = pd.read_csv("/content/heart_2020_cleaned.csv")

df.head(10)

df.info()

"""## Seleccion de variables"""

#Pasamos las columnas tipo object a category
df['HeartDisease'] = df['HeartDisease'].astype('category')
df['Smoking'] = df['Smoking'].astype('category')
df['AlcoholDrinking'] = df['AlcoholDrinking'].astype('category')
df['Stroke'] = df['Stroke'].astype('category')
df['DiffWalking'] = df['DiffWalking'].astype('category')
df['Sex'] = df['Sex'].astype('category')
df['AgeCategory'] = df['AgeCategory'].astype('category')
df['Race'] = df['Race'].astype('category')
df['Diabetic'] = df['Diabetic'].astype('category')
df['PhysicalActivity'] = df['PhysicalActivity'].astype('category')
df['GenHealth'] = df['GenHealth'].astype('category')
df['Asthma'] = df['Asthma'].astype('category')
df['KidneyDisease'] = df['KidneyDisease'].astype('category')
df['SkinCancer'] = df['SkinCancer'].astype('category')

df.info()

X = df.drop('HeartDisease', axis=1)
y = df['HeartDisease']

"""## Estadistica Descriptiva"""

# Crear el perfil de pandas profiling
profile = ProfileReport(df, title="Pandas Profiling Report - Heart Disease", explorative=True)

# Ver en notebook
profile.to_notebook_iframe()

print("\nForma del dataset:", df.shape)

#Describimos variables numericas
df.describe()

#BoxPlot para las numericas
num_cols = df.select_dtypes(include='float64').columns

for col in num_cols:
    plt.figure(figsize=(6,4))
    sns.boxplot(x=col, data=df)
    plt.title(f'Distribución de {col}')
    plt.xlabel(col)
    plt.ylabel('Frecuencia')
    plt.tight_layout()
    plt.show()

#Describimos variables categoricas
df.describe(include='category').T

#Diagrama de barras para las categoricas
cat_cols = df.select_dtypes(include='category').columns

for col in cat_cols:
    plt.figure(figsize=(6,4))
    sns.countplot(x=col, data=df, palette='Set2')
    plt.title(f'Distribución de {col}')
    plt.xticks(rotation=45)
    plt.xlabel(col)
    plt.ylabel('Frecuencia')
    plt.tight_layout()
    plt.show()

#Distribucion de la variable objetivo
df['HeartDisease'].value_counts(normalize=True) * 100

"""## Limpieza de nulos"""

print("\nCantidad de valores nulos por columna:")
print(df.isnull().sum())

df[df.isnull().any(axis=1)].head(10)

df = df.dropna()
df.info()

"""## Analisis de Correlaciones para Redundancia"""

#Redundancia para variables numericas
# Filtramos solo variables numéricas
num_vars = df.select_dtypes(include=['number'])

# Calculamos la matriz de correlación
corr = num_vars.corr(method='pearson')

# Mostramos un mapa de calor
plt.figure(figsize=(10,8))
sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)
plt.title("Correlación entre variables numéricas")
plt.show()

#Redundancia entre variables categoricas
def cramers_v(x, y):
    confusion_matrix = pd.crosstab(x, y)
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum().sum()
    r, k = confusion_matrix.shape
    return np.sqrt(chi2 / (n * (min(k, r) - 1)))

# Creamos la matriz de Cramer's V
cat_vars = df.select_dtypes(include='category').columns
cramer_matrix = pd.DataFrame(index=cat_vars, columns=cat_vars)

for var1 in cat_vars:
    for var2 in cat_vars:
        if var1 == var2:
            cramer_matrix.loc[var1, var2] = 1
        else:
            cramer_matrix.loc[var1, var2] = cramers_v(df[var1], df[var2])

cramer_matrix = cramer_matrix.astype(float)

plt.figure(figsize=(10,8))
sns.heatmap(cramer_matrix, annot=True, cmap='Purples')
plt.title("Asociación (Cramer's V) entre variables categóricas")
plt.show()

df.hist()

"""division 70-30 , se balancea solo el 70%"""

from sklearn.model_selection import train_test_split

# Separar variables predictoras (X) y variable objetivo (y)
X = df.drop('HeartDisease', axis=1)
y = df['HeartDisease']

# División 70-30 (entrenamiento-prueba)
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,          # 30% de los datos para prueba
    random_state=42,        # Semilla para reproducibilidad
    stratify=y              # Mantiene la proporción de clases
)

print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de prueba:", X_test.shape)
print("Distribución en entrenamiento:\n", y_train.value_counts(normalize=True))
print("Distribución en prueba:\n", y_test.value_counts(normalize=True))

"""##Balanceo"""

# Identificar columnas categóricas y numéricas
categorical_features = X_train.select_dtypes(include='category').columns
numerical_features = X_train.select_dtypes(include=np.number).columns

# Crear preprocesador
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('num', 'passthrough', numerical_features)
    ],
    remainder='drop'
)

# Aplicar preprocesamiento al conjunto de entrenamiento
X_train_processed = preprocessor.fit_transform(X_train)

# Obtener nombres de columnas después del OneHotEncoder
encoded_cols = preprocessor.get_feature_names_out()

# Convertir a DataFrame con nombres correctos
X_train_processed_df = pd.DataFrame(
    X_train_processed.toarray() if hasattr(X_train_processed, "toarray") else X_train_processed,
    columns=encoded_cols
)

# Aplicar SMOTE con balanceo al 20%
smote = SMOTE(sampling_strategy=1.0, random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train_processed_df, y_train)

# Asegurar que y_train_bal sea una Serie de pandas
y_train_bal = pd.Series(y_train_bal, name='HeartDisease')

# Mostrar resultados
print("Distribución original:\n", y_train.value_counts(), "\n")
print("Distribución después del balanceo (100%):\n", y_train_bal.value_counts())
print("\nForma de X_train_bal después del balanceo y codificación:", X_train_bal.shape)

#  Obtener nombres de columnas del preprocesador
encoded_cols = preprocessor.get_feature_names_out()

# Convertir a DataFrame asegurando la forma correcta
X_train_bal_df = pd.DataFrame(
    X_train_bal,
    columns=encoded_cols  # deben coincidir en cantidad con X_train_bal.shape[1]
)

# Añadir la variable objetivo balanceada
X_train_bal_df['HeartDisease'] = y_train_bal.values

# Revisar
print(X_train_bal_df.head())
print("\nForma:", X_train_bal_df.shape)

"""##Creacion de Nuevas Variables"""

# BMI_Age_Interaction
#efecto combinado del IMC y la edad. Un IMC alto es más riesgoso en personas mayores.
X['BMI_Age_Interaction'] = X['BMI'] * X['AgeCategory'].cat.codes

# Health_Conditions_Count
#Suma de condiciones presentes: Stroke (Derrame cerebral),Diabetes, Enfermedad renal,Asma y Cáncer de piel

X['Health_Conditions_Count'] = (
    (X['Stroke'] == 'Yes').astype(int) +
    (X['Diabetic'].isin(['Yes', 'Yes (during pregnancy)'])).astype(int) +
    (X['KidneyDisease'] == 'Yes').astype(int) +
    (X['Asthma'] == 'Yes').astype(int) +
    (X['SkinCancer'] == 'Yes').astype(int)
)

#Suma de hábitos poco saludables: Fuma, Bebe Alcohol y No Hace Actividad Fisica
X['Unhealthy_Lifestyle'] = (
    (X['Smoking'] == 'Yes').astype(int) +
    (X['AlcoholDrinking'] == 'Yes').astype(int) +
    (X['PhysicalActivity'] == 'No').astype(int)
)

#Conversión de categorías a números:
#Poor (Mala) = 1
#Fair (Regular) = 2
#Good (Buena) = 3
#Very good (Muy buena) = 4
#Excellent (Excelente) = 5
health_mapping = {'Poor': 1, 'Fair': 2, 'Good': 3, 'Very good': 4, 'Excellent': 5}
X['GenHealth_Score'] = X['GenHealth'].map(health_mapping).astype('float64')  # ← AGREGAR .astype('float64')

#Relación entre calidad de salud y horas de sueño.
X['Health_Sleep_Ratio'] = X['GenHealth_Score'] / (X['SleepTime'] + 1)

# 6. BMI_Category
#Clasificación según IMC:
#Underweight (Bajo peso): IMC < 18.5
#Normal: 18.5 ≤ IMC < 25
#Overweight (Sobrepeso): 25 ≤ IMC < 30
#Obese (Obeso): IMC ≥ 30

X['BMI_Category'] = pd.cut(
    X['BMI'],
    bins=[0, 18.5, 25, 30, 100],
    labels=['Underweight', 'Normal', 'Overweight', 'Obese']
)

#1 si edad ≥ 65 años (categorías: 65-69, 70-74, 75-79, 80+)
#0 en caso contrario
#Interpretación: Indicador de población adulta mayor.

age_senior = ['65-69', '70-74', '75-79', '80 or older']
X['Is_Senior'] = X['AgeCategory'].isin(age_senior).astype(int)

#ías totales con problemas de salud (física + mental) en los últimos 30 días.
X['Total_Unhealthy_Days'] = X['PhysicalHealth'] + X['MentalHealth']

X['CV_Risk_Score'] = (
    X['Health_Conditions_Count'] * 2 +
    X['Unhealthy_Lifestyle'] +
    (X['DiffWalking'] == 'Yes').astype(int) * 2 +
    X['Is_Senior']
)

# BMI_Activity_Risk
#Riesgo por obesidad sedentaria.
X['BMI_Activity_Risk'] = X['BMI'] * (X['PhysicalActivity'] == 'No').astype(int)

nuevas_vars = [
    'BMI_Age_Interaction',
    'Health_Conditions_Count',
    'Unhealthy_Lifestyle',
    'GenHealth_Score',
    'Health_Sleep_Ratio',
    'BMI_Category',
    'Is_Senior',
    'Total_Unhealthy_Days',
    'CV_Risk_Score',
    'BMI_Activity_Risk'
]

print("NUEVAS VARIABLES CREADAS:")
print(X[nuevas_vars].head(10))

print("TIPOS DE DATOS DE NUEVAS VARIABLES:")
print(X[nuevas_vars].dtypes)

"""##Descargar

Datos balanceados para entrenar el modelo
"""

# Obtener los nombres de las columnas luego del preprocesamiento
encoded_cols = preprocessor.get_feature_names_out()

# Reconstruir DataFrame con las columnas codificadas y balanceadas
df_final = pd.DataFrame(X_train_bal, columns=encoded_cols)
df_final['HeartDisease'] = y_train_bal.values

# Guardar todo en un solo archivo CSV
df_final.to_csv('heart_disease_prepared((1).csv', index=False)

print("Archivo 'heart_disease_prepared.csv' creado correctamente.")
print("Tamaño final del dataset preparado:", df_final.shape)
print("Distribución de clases:\n", df_final['HeartDisease'].value_counts())

df_final.head(10)

"""Datos originales de prueba"""

# Aplicar el mismo preprocesamiento al conjunto de prueba
X_test_processed = preprocessor.transform(X_test)

# Convertir a DataFrame con las mismas columnas codificadas
X_test_processed_df = pd.DataFrame(
    X_test_processed.toarray() if hasattr(X_test_processed, "toarray") else X_test_processed,
    columns=encoded_cols
)

# Agregar la variable objetivo (y_test)
df_test = pd.DataFrame(X_test_processed_df)
df_test['HeartDisease'] = y_test.values

# Guardar el conjunto de prueba en un archivo CSV
df_test.to_csv('heart_disease_test.csv', index=False)

# Confirmar resultados
print("Archivo 'heart_disease_test.csv' creado correctamente.")
print("Tamaño del conjunto de prueba:", df_test.shape)
print("Distribución de clases en test:\n", df_test['HeartDisease'].value_counts())

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
import pandas as pd

# 1. División 70-30 (sin tocar las variables categóricas)
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.30,
    random_state=42,
    stratify=y
)

print("Distribución original en entrenamiento:")
print(y_train.value_counts())
print(f"\nForma de X_train antes del balanceo: {X_train.shape}")

# 2. Para SMOTE, necesitamos convertir temporalmente a numérico
# pero luego restauramos las categorías originales
X_train_numeric = X_train.copy()

# Convertir categóricas a códigos numéricos temporalmente
categorical_cols = X_train.select_dtypes(include='category').columns
category_mappings = {}

for col in categorical_cols:
    category_mappings[col] = X_train[col].cat.categories
    X_train_numeric[col] = X_train[col].cat.codes

# 3. Aplicar SMOTE
smote = SMOTE(sampling_strategy=1.0, random_state=42)
X_train_bal_numeric, y_train_bal = smote.fit_resample(X_train_numeric, y_train)

# 4. Restaurar las variables categóricas originales
X_train_bal = X_train_bal_numeric.copy()

for col in categorical_cols:
    # Convertir los códigos de vuelta a categorías
    X_train_bal[col] = pd.Categorical.from_codes(
        X_train_bal_numeric[col].astype(int),
        categories=category_mappings[col]
    )

# Asegurar que y_train_bal sea una Serie
y_train_bal = pd.Series(y_train_bal, name='HeartDisease')

# 5. Mostrar resultados
print("\n" + "="*50)
print("Distribución después del balanceo:")
print(y_train_bal.value_counts())
print(f"\nForma de X_train_bal: {X_train_bal.shape}")
print(f"\nTipos de datos en X_train_bal:")
print(X_train_bal.dtypes)
print(f"\n¿Las columnas categóricas siguen siendo 'category'? {X_train_bal.select_dtypes(include='category').columns.tolist()}")

# Verificar algunas filas
print("\nPrimeras filas de X_train_bal:")
print(X_train_bal.head())

import pandas as pd

# Crear archivo combinado de entrenamiento
train_bal_combined = X_train_bal.copy()
train_bal_combined['HeartDisease'] = y_train_bal
train_bal_combined.to_csv('heart_disease_train.csv', index=False)
print("✓ heart_disease_train.csv descargado")

# Crear archivo combinado de prueba
test_combined = X_test.copy()
test_combined['HeartDisease'] = y_test
test_combined.to_csv('heart_disease_test.csv', index=False)
print("✓ heart_disease_test.csv descargado")

print("\n" + "="*50)
print("RESUMEN DE ARCHIVOS DESCARGADOS:")
print("="*50)
print(f"1. heart_disease_train.csv - {train_bal_combined.shape[0]} filas × {train_bal_combined.shape[1]} columnas")
print(f"   - Balanceado al 100% con SMOTE")
print(f"   - Variables categóricas originales (sin dummies)")
print(f"\n2. heart_disease_test.csv - {test_combined.shape[0]} filas × {test_combined.shape[1]} columnas")
print(f"   - Sin balancear (distribución original)")
print(f"   - Variables categóricas originales (sin dummies)")

# Mostrar distribución de clases
print("\n" + "="*50)
print("DISTRIBUCIÓN DE CLASES:")
print("="*50)
print("Train (balanceado):")
print(train_bal_combined['HeartDisease'].value_counts())
print("\nTest (original):")
print(test_combined['HeartDisease'].value_counts())

"""##"""